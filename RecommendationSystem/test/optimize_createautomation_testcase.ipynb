{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b6b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04bfc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import base64\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "subscription_key = \"CpcP5WHUW180iluo6CudtpwSnjjvwcEqNbpq8cdVsXu3zkMQqQVgJQQJ99BBACHYHv6XJ3w3AAAAACOGPcpj\"\n",
    "\n",
    "endpoint = os.getenv(\"ENDPOINT_URL\", \"https://ai-21t10208850765ai125704117754.cognitiveservices.azure.com/\")\n",
    "deployment = os.getenv(\"DEPLOYMENT_NAME\", \"gpt-4.1\")\n",
    "subscription_key = os.getenv(\"AZURE_OPENAI_API_KEY\", subscription_key)\n",
    "\n",
    "# Initialize Azure OpenAI client with key-based authentication\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key,\n",
    "    api_version=\"2025-01-01-preview\",\n",
    ")\n",
    "\n",
    "\n",
    "def completion_func(message : str = \"\") : \n",
    "    response = client.chat.completions.create(\n",
    "        model=deployment,\n",
    "        messages=message,\n",
    "        max_tokens=4090,\n",
    "        temperature=0.0,\n",
    "        top_p=1.0,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0,\n",
    "        # stop=None,\n",
    "        # stream=False\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    if content is None:\n",
    "        # Kiểm tra kết quả bộ lọc nội dung để xác định nguyên nhân\n",
    "        filter_results = response.choices[0].message.content_filter_results\n",
    "    if filter_results and filter_results.get('violence', {}).get('filtered', False):\n",
    "        print(\"Nội dung bị chặn do có yếu tố bạo lực.\")\n",
    "    else:\n",
    "        print(\"Không có nội dung nào được trả về.\")\n",
    "    \n",
    "    # Xử lý nội dung bình thường\n",
    "    print(\"Nội dung trả về: \", content)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "618abec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Bạn là một hệ thống sinh test case tự động cho các bài toán lập trình.\n",
    "Hãy sinh ra K test case đa dạng (bao gồm cả edge case) cho bài toán sau, mỗi test case gồm input và output tương ứng.\n",
    "Nếu có thể, hãy giải thích ngắn gọn ý nghĩa của từng test case.\n",
    "\n",
    "Ví dụ:\n",
    "Bài_toán: Tính tổng hai số\n",
    "Mô_tả: Viết một hàm nhận vào hai số và trả về tổng của chúng. Input là a và b, output là tổng của a và b. Giới hạn của a và b là từ 0 đến 10^9.\n",
    "\n",
    "Kết quả mong muốn (dưới dạng JSON):\n",
    "[\n",
    "    {{\"input\": [3, 5], \"output\": 8, \"description\": \"Tổng hai số nguyên dương.\"}},\n",
    "    {{\"input\": [0, 0], \"output\": 0, \"description\": \"Cả hai số là 0.\"}},\n",
    "    {{\"input\": [-1000, 20000], \"output\": 19000, \"description\": \"Một số âm, một số dương.\"}},\n",
    "    {{\"input\": [1000000000, 1000000000], \"output\": 2000000000, \"description\": \"Cả hai số đạt giá trị lớn nhất.\"}},\n",
    "    {{\"input\": [1, 999999999], \"output\": 1000000000, \"description\": \"Một số nhỏ nhất, một số lớn nhất.\"}},\n",
    "    {{\"input\": [-500, -500], \"output\": -1000, \"description\": \"Cả hai số đều âm.\"}}\n",
    "]\n",
    "\n",
    "Bài toán: {problem}\n",
    "Hãy sinh {K} test case theo định dạng trên.\n",
    "Chỉ trả về kết quả cuối cùng dưới dạng JSON, không kèm bất kỳ giải thích hoặc văn bản nào khác.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fddfaa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.llm import AzureOpenAILLM\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "dotenv_path = \"D:/UbuntuSystem/OnlineCodingCompetition/RecommendationSystem/.env\"\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "subscription_key = os.getenv(\"OPENAI_KEY\")\n",
    "endpoint = os.getenv(\"endpoint\")\n",
    "DEPLOYMENT_NAME = os.getenv(\"DEPLOYMENT_NAME\", \"gpt-4.1\")\n",
    "api_version= os.getenv(\"api_version\", \"2025-01-01-preview\")\n",
    "if not subscription_key or not endpoint:\n",
    "    raise ValueError(\"Please set the OPENAI_KEY and endpoint environment variables.\")\n",
    "\n",
    "llm = AzureOpenAILLM(\n",
    "    model_name=DEPLOYMENT_NAME,\n",
    "    azure_endpoint=endpoint,\n",
    "    api_version=api_version, \n",
    "    api_key=subscription_key,\n",
    "    # temperature=0.7,\n",
    "    # max_tokens=4096,\n",
    "    # top_p=0.6,\n",
    ")\n",
    "\n",
    "\n",
    "def generate_test_cases(code: str, K_candidates: int, problem_id : int) -> [dict]:\n",
    "    \"\"\"\n",
    "    Generate test cases for a given code snippet based on the provided prompt.\n",
    "    \n",
    "    Args:\n",
    "        code (str): The code snippet for which to generate test cases.\n",
    "        K (int): The number of initial test cases to generate.\n",
    "        N (int): The number of additional test cases to generate.\n",
    "    \n",
    "    Returns:\n",
    "        str: A formatted string containing the generated test cases.\n",
    "    \"\"\"\n",
    "    # Format the prompt with the specified number of test cases\n",
    "    formatted_prompt = prompt.format(K=K_candidates, problem=code)\n",
    "    response = llm.invoke(formatted_prompt)\n",
    "    if not response or not response.content:\n",
    "        raise ValueError(\"No response received from the LLM.\")\n",
    "    response_content = response.content.strip()\n",
    "    result = json.loads(response_content)\n",
    "    return result\n",
    "title = \"Nhân 2 số nguyên\"\n",
    "description = \"Viết một hàm nhận vào hai số và trả về tích của chúng. Input là a và b, output là tích của a và b. Giới hạn của a và b là từ 0 đến 10^9.\"\n",
    "response = generate_test_cases(f\"Bài_toán:{title}/n Mô_tả:{description}\",5,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd9cf7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
